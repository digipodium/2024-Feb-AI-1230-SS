{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DRY BEAN CLASS PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ml specific imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# algorithm\n",
    "# linear classfication\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# tree classfication\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# neighbour classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# naive bayes classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# support vection machine classification\n",
    "from sklearn.svm import SVC\n",
    "# ensemble\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load the dataset and explore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Dry_Bean_Dataset.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make the target column as numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "enc = LabelEncoder()\n",
    "y = enc.fit_transform(df['Class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class', axis=1) # features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pipelines for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "# 1. Logistic Regression\n",
    "k = 10\n",
    "clf1 = Pipeline([\n",
    "        ('feature_selection', SelectKBest(chi2, k=k)),\n",
    "        ('classification', LogisticRegression(solver='saga'))\n",
    "])\n",
    "# 2. Decision Tree\n",
    "clf2 = Pipeline([\n",
    "        ('feature_selection', SelectKBest(chi2, k=k)),\n",
    "        ('classification', DecisionTreeClassifier())\n",
    "])\n",
    "# 3. Nearest Neighbors\n",
    "clf3 = Pipeline([\n",
    "        ('feature_selection', SelectKBest(chi2, k=k)),\n",
    "        ('classification', KNeighborsClassifier())\n",
    "])\n",
    "# 4. Gaussian Naive Bayes\n",
    "clf4 = Pipeline([\n",
    "        ('feature_selection', SelectKBest(chi2, k=k)),\n",
    "        ('classification', GaussianNB())\n",
    "])\n",
    "\n",
    "# 5. Support Vector Machine\n",
    "clf5 = Pipeline([\n",
    "        ('feature_selection', SelectKBest(chi2, k=k)),\n",
    "        ('classification', SVC())\n",
    "])\n",
    "\n",
    "# 6. Random Forest\n",
    "clf6 = Pipeline([\n",
    "        ('feature_selection', SelectKBest(chi2, k=k)),\n",
    "        ('classification', RandomForestClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42)\n",
    "# train the model\n",
    "clf1.fit(X_train, y_train)\n",
    "clf2.fit(X_train, y_train)\n",
    "clf3.fit(X_train, y_train)\n",
    "clf4.fit(X_train, y_train)\n",
    "clf5.fit(X_train, y_train)\n",
    "clf6.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred1 = clf1.predict(X_test)\n",
    "ypred2 = clf2.predict(X_test)\n",
    "ypred3 = clf3.predict(X_test)\n",
    "ypred4 = clf4.predict(X_test)\n",
    "ypred5 = clf5.predict(X_test)\n",
    "ypred6 = clf6.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(7,7))\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_test, ypred1), \n",
    "    display_labels=enc.classes_\n",
    ").plot(ax=ax, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"LOGISTIC REGRESSION\")\n",
    "print('---'*20)\n",
    "print(classification_report(y_test, ypred1, target_names=enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"DECISION TREE CLF\")\n",
    "print('---'*20)\n",
    "print(classification_report(y_test, ypred2, target_names=enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SUPPORT VECTOR CLF\")\n",
    "print('---'*20)\n",
    "print(classification_report(y_test, ypred5, target_names=enc.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(7,7))\n",
    "ConfusionMatrixDisplay(\n",
    "    confusion_matrix(y_test, ypred6), \n",
    "    display_labels=enc.classes_\n",
    ").plot(ax=ax, colorbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model, encoder\n",
    "import joblib\n",
    "joblib.dump(clf6, 'saved_model.pkl')\n",
    "joblib.dump(enc, 'saved_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 march 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_input(\n",
    "    area, perimeter, majoraxislength,\n",
    "    minoraxislength, aspectration, eccentricity,\n",
    "    convexarea, equivdiameter, extent, solidity, \n",
    "    roundness, compactness, shapefactor1,\n",
    "    shapefactor2, shapefactor3, shapefactor4\n",
    "):\n",
    "    data = {'Area': area,\n",
    "        'Perimeter': perimeter,\n",
    "        'MajorAxisLength': majoraxislength,\n",
    "        'MinorAxisLength': minoraxislength,\n",
    "        'AspectRation': aspectration,\n",
    "        'Eccentricity': eccentricity,\n",
    "        'ConvexArea': convexarea,\n",
    "        'EquivDiameter': equivdiameter,\n",
    "        'Extent': extent,\n",
    "        'Solidity': solidity,\n",
    "        'roundness': roundness,\n",
    "        'Compactness': compactness,\n",
    "        'ShapeFactor1': shapefactor1,\n",
    "        'ShapeFactor2': shapefactor2,\n",
    "        'ShapeFactor3':shapefactor3,\n",
    "        'ShapeFactor4': shapefactor4\n",
    "    }\n",
    "    X_inp = pd.DataFrame([data])            # create a dataframe\n",
    "    clf = joblib.load('saved_model.pkl')    # load the model\n",
    "    enc = joblib.load('saved_encoder.pkl')  # load the encoder\n",
    "    y_pred = clf.predict(X_inp)             # predict the class\n",
    "    # print(y_pred, enc.inverse_transform(y_pred)[0])\n",
    "    return enc.inverse_transform(y_pred)[0] # bean class name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trick to get the list of all parameters for the function when you have a lot of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\", \".join(df.columns.tolist()).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the function X.iloc[0].todict()\n",
    "data = {'Area': 28395.0,\n",
    " 'Perimeter': 1000.291,\n",
    " 'MajorAxisLength': 608.1781167,\n",
    " 'MinorAxisLength': 173.888747,\n",
    " 'AspectRation': 1.197191424,\n",
    " 'Eccentricity': 0.549812187,\n",
    " 'ConvexArea': 28715.0,\n",
    " 'EquivDiameter': 190.1410973,\n",
    " 'Extent': 0.763922518,\n",
    " 'Solidity': 0.988855999,\n",
    " 'roundness': 0.858027126,\n",
    " 'Compactness': 0.913357755,\n",
    " 'ShapeFactor1': 0.007331506,\n",
    " 'ShapeFactor2': 0.003147289,\n",
    " 'ShapeFactor3': 0.834222388,\n",
    " 'ShapeFactor4': 0.998723889\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simplest version for Gradio ui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ui = gr.Interface(\n",
    "    predict_input,\n",
    "    inputs = [\n",
    "        gr.Number(label='Area'),\n",
    "        gr.Number(label='Perimeter', step=.01),\n",
    "        gr.Number(label='MajorAxisLength', step=.01),\n",
    "        gr.Number(label='MinorAxisLength', step=.01),\n",
    "        gr.Number(label='AspectRation', step=.01),\n",
    "        gr.Number(label='Eccentricity', step=.01),\n",
    "        gr.Number(label='ConvexArea'),\n",
    "        gr.Number(label='EquivDiameter', step=.01),\n",
    "        gr.Number(label='Extent', step=.01),\n",
    "        gr.Number(label='Solidity', step=.01),\n",
    "        gr.Number(label='roundness', step=.01),\n",
    "        gr.Number(label='Compactness', step=.01),\n",
    "        gr.Number(label='ShapeFactor1', step=.01),\n",
    "        gr.Number(label='ShapeFactor2', step=.01),\n",
    "        gr.Number(label='ShapeFactor3', step=.01),\n",
    "        gr.Number(label='ShapeFactor4', step=.01)\n",
    "    ],\n",
    "    outputs = 'text',\n",
    "    title = \"Dry Bean Classification\",\n",
    "    examples=[\n",
    "        [28395.0, 1000.291, 608.1781167, 173.888747, 1.197191424, 0.549812187, 28715.0, 190.1410973, 0.763922518, 0.988855999, 0.858027126, 0.913357755, 0.007331506, 0.003147289, 0.834222388, 0.998723889]\n",
    "    ]\n",
    ")\n",
    "ui.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlbatch24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
